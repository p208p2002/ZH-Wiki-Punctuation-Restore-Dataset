import unicodedata
from typing import List

USE_ZH_PUNCTUATION = [
    'ï¼Œ',
    'ã€',
    'ã€‚',
    'ï¼Ÿ',
    'ï¼',
    'ï¼›',
]

def isFull(c:str)->bool:
    # å…¨å½¢å­—å…ƒçš„ unicode ç·¨ç¢¼æ˜¯å¾ 65281 åˆ° 65374
    return ord(c) in range(65281,65374+1)

def isHalf(c:str)->bool:
    # åŠå½¢å­—å…ƒçš„ unicode ç·¨ç¢¼æ˜¯å¾ 33 åˆ° 126
    return ord(c) in range(33,126+1)

def full2half(c: str) -> str:
    if isFull(c):
        return chr(ord(c)-65248)
    return c


def half2full(c: str) -> str:
    if isHalf(c):
        return chr(ord(c)+65248)
    return c

def ch_text_norm(text):
    # å°‡æ‰€æœ‰ç¬¦è™Ÿè½‰æ›è‡³å…¨å½¢
    # è‹±æ–‡æˆ–æ˜¯æ•¸å­—è½‰æ›æˆåŠå½¢
    # ç¬¦è™Ÿç©ºç™½ç­‰ç§»é™¤
    # https://en.wikipedia.org/wiki/Template:General_Category_(Unicode)
    text = list(text)
    for t_id,c in enumerate(text):
        if unicodedata.category(c)[0] == 'P':
            new_char = half2full(c)
            text[t_id] = new_char
        if unicodedata.category(c)[0] == 'N' or unicodedata.category(c) in ['Lu','Ll']:
            new_char = full2half(c)
            text[t_id] = new_char
        if unicodedata.category(c)[0] in ['Z','O']:
            text[t_id] = "" # soft del
        if unicodedata.category(c) in ['So']:
            text[t_id] = "" # soft del
    
    return ''.join(text)

def clean_punct(text,keep_use_punct=False):
    text = list(text)
    for t_id,c in enumerate(text):
        if keep_use_punct == True:
            if unicodedata.category(c)[0] == 'P' and c not in USE_ZH_PUNCTUATION:
                text[t_id] = ""
        elif keep_use_punct == False:
            if unicodedata.category(c)[0] == 'P':
                text[t_id] = ""
    return ''.join(text)

def gen_input_and_bio(text: str) -> List[str]:
    tokens = list(text)
    bio = []
    tokens_wo_punct = []
    for t_id, token in enumerate(tokens):
        if token in USE_ZH_PUNCTUATION:
            if len(bio) > 0 and bio[-1] == 'O':
                bio.pop(-1)
            bio.append(f"S-{token}")
        else:
            bio.append('O')
            tokens_wo_punct.append(token)
    return tokens_wo_punct,bio
        
# text = "}ã€(ï¼ˆ)ï¼‰æˆ‘ğŸ™‚ä»Š  /å¤©,å»è²·é£¯ï¼Œ.ã€‚ï¼ï¼¡|0Aâ€˜â€™â€œâ€''""ã€Œã€ã€ã€ï¼Ÿ?"
# text = "æˆ‘ä»Šå¤©ï¼Œå»è²·èŒƒã€‚"
# print(text,len(text))
# print(text:=clean_punct(ch_text_norm(text),keep_use_punct=True),len(text))
# print(bio_tag:=gen_bio_tag(text),len(bio_tag[0]),len(bio_tag[-1]))


